import streamlit as st
import pdfplumber
import io
import re
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import easyocr
import zipfile
import unicodedata
import pandas as pd
import gspread
import os  # <--- Ë£ú‰∏äÊºèÊéâÁöÑÂ∞éÂÖ•
from google.oauth2.service_account import Credentials

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 1. Èõ≤Á´ØË®òÊÜ∂Ê®°ÁµÑ (‰øùÊåÅÂéüÊ®£)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def get_gsheet_client():
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    try:
        creds_info = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        gc = gspread.authorize(creds)
        return gc.open("Âú∞ÊîøAIÂ≠∏ÁøíÂ∫´").sheet1
    except: return None

def load_cloud_memory():
    sheet = get_gsheet_client()
    if sheet:
        try:
            records = sheet.get_all_records()
            return {str(r['wrong']): str(r['right']) for r in records if 'wrong' in r}
        except: return {}
    return {}

def save_to_cloud(wrong, right):
    sheet = get_gsheet_client()
    if sheet:
        try: sheet.append_row([str(wrong), str(right)])
        except: pass

def ai_smart_fix(text):
    if not text: return text
    memory = load_cloud_memory()
    for wrong, right in memory.items():
        if str(wrong) in text:
            text = text.replace(str(wrong), str(right))
    return text

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 2. ÂéüÊúâÊàêÂäüËæ®Ë≠òÈÇèËºØ (ÂÆåÂÖ®‰øùÁïôÔºå‰∏çÂãï‰ªª‰ΩïÊ≠£Ââá)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Ë®≠ÂÆö Poppler Ë∑ØÂæë
LOCAL_POPPLER_PATH = r"C:\Users\User\Desktop\pdf_explain new\poppler-25.12.0\Library\bin"
POPPLER_PATH = LOCAL_POPPLER_PATH if os.path.exists(LOCAL_POPPLER_PATH) else None

@st.cache_resource
def load_ocr():
    return easyocr.Reader(['ch_tra', 'en'], gpu=False)

def normalize(text):
    if not text: return ""
    return unicodedata.normalize("NFKC", re.sub(r'\s+', '', text))

def fix_addr_post_process(text: str) -> str:
    if not text: return text
    # ÂÖàÈÅéÊøæÈõ≤Á´ØË®òÊÜ∂
    text = ai_smart_fix(text)
    # ÊÇ®ÁöÑÂéüÊ†°Ê≠£Ë°®
    _ADDR_CHAR_MAP = {'ËÄã': 'Ëá∫', 'ËÄ∏': 'Ëá∫', 'Â≠ø': 'Â≠∏', 'Â≠Ω': 'Â≠∏', 'Â£Ü': 'Â≠∏', 'Ë¶É': 'Âçó'}
    for wrong, right in _ADDR_CHAR_MAP.items():
        text = text.replace(wrong, right)
    text = re.sub(r'(\d)\s+(\d)', r'\1\2', text)
    _ADDR_CJK = r'[ÈáåÈÑ∞Ë∑ØÊÆµÂ∑∑ÂºÑËôüË°óÂçÄÂ∏ÇÁ∏£ÈÑâÈéÆÊùë]'
    text = re.sub(rf'({_ADDR_CJK})\s+(\d)', r'\1\2', text)
    text = re.sub(rf'(\d)\s+({_ADDR_CJK})', r'\1\2', text)
    return text

def ocr_with_best_result(ocr, img_gray: np.ndarray) -> tuple:
    fx, fy = 4, 4
    b1 = cv2.resize(img_gray, None, fx=fx, fy=fy, interpolation=cv2.INTER_LANCZOS4)
    results = ocr.readtext(b1, detail=0)
    raw = "".join(results).strip()
    processed = fix_addr_post_process(raw)
    return processed, "Standard"

def extract_addr_from_image_stream(page, ocr, debug_log: list):
    words = page.extract_words()
    target = next((w for w in words if w['text'] in ['Âú∞ÂùÄ', '‰ΩèÂùÄ']), None)
    if not target: return ""
    addr_imgs = [img for img in page.images if abs(img['top'] - target['top']) < 5]
    if not addr_imgs: return ""
    try:
        raw = addr_imgs[0]['stream'].get_data()
        buf = np.frombuffer(raw, dtype=np.uint8)
        decoded = cv2.imdecode(buf, cv2.IMREAD_GRAYSCALE)
        val, _ = ocr_with_best_result(ocr, decoded)
        return f"{target['text']} {val}"
    except: return ""

# ‰∏âÂ§ßËß£ÊûêÊ†∏ÂøÉÔºàÂÆåÂÖ®‰∏çÂãïÂÖßÈÉ®ÈÇèËºØÔºâ
def process_Ë°®Ê†ºÂºè(pdf, ocr, all_imgs, fmt):
    output, debug = [], []
    for i, page in enumerate(pdf.pages):
        page_text = []
        tables = page.extract_tables()
        for table in tables:
            for row in table:
                cells = [c.strip().replace("\n", "") if c else "" for c in row]
                if not any(cells): continue
                if normalize(cells[0]) in ["Âú∞ÂùÄ", "‰ΩèÂùÄ"] and not any(cells[1:]):
                    line = extract_addr_from_image_stream(page, ocr, debug)
                else:
                    line = "  ".join(c for c in cells if c)
                page_text.append(line)
        output.append(f"===== Á¨¨ {i+1} È†Å =====\n" + "\n".join(page_text))
    return "\n\n".join(output), debug

def process_Áæ§Áíá(pdf, ocr, all_imgs):
    output = []
    for i, page in enumerate(pdf.pages):
        lines = [ "  ".join(filter(None, [c.replace("\n","") for c in row])) for table in page.extract_tables() for row in table ]
        output.append(f"===== Á¨¨ {i+1} È†Å =====\n" + "\n".join(lines))
    return "\n\n".join(output), []

def process_Ë¨ÑÊú¨(pdf, ocr, all_imgs):
    output = []
    for i, page in enumerate(pdf.pages):
        txt = page.extract_text() or ""
        output.append(f"===== Á¨¨ {i+1} È†Å =====\n" + txt)
    return "\n\n".join(output), []

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 3. Excel ÁµêÊßãÂåñËß£Êûê (Âº∑ÂåñÂú∞ÊÆµ„ÄÅÈù¢Á©ç„ÄÅÊâÄÊúâÊ¨ä‰∫∫Êì∑Âèñ)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def parse_for_excel(text):
    # Ëß£ÊûêÂâçÂÖàÂ•óÁî®Èõ≤Á´ØË®òÊÜ∂
    text = ai_smart_fix(text)
    
    data = {
        "Âú∞ËôüÂÖ®Âêç": "", "Âú∞Ëôü": "", "Èù¢Á©ç": "", 
        "ÂÖ¨ÂëäÂúüÂú∞ÁèæÂÄº": "", "ÊâÄÊúâÊ¨ä‰∫∫": "", "Áµ±‰∏ÄÁ∑®Ëôü": "", "Âú∞ÂùÄ": ""
    }
    
    # ‰øÆÊ≠£ÔºöÂú∞ÊÆµÊäìÂèñÊõ¥ÂØ¨ÂÆπ
    m_loc = re.search(r'([^\s]+(?:Á∏£|Â∏Ç)[^\s]+(?:ÂçÄ|ÈÑâ|ÈéÆ|Â∏Ç)[^\s]+ÊÆµ)', text)
    if m_loc: data["Âú∞ËôüÂÖ®Âêç"] = m_loc.group(1)
    
    # ‰øÆÊ≠£ÔºöÂú∞ËôüÊäìÂèñ
    m_no = re.search(r'(\d{4}-\d{4})', text)
    if m_no: data["Âú∞Ëôü"] = m_no.group(1)
    
    # ‰øÆÊ≠£ÔºöÈù¢Á©çÊäìÂèñ (ÊîØÊè¥ sample.xlsx ‰∏≠ÁöÑÈÄóËôüËàáÁ©∫Ê†º)
    m_area = re.search(r'Èù¢Á©ç\s*[,Ôºå]?\s*([\d.]+)', text)
    if m_area: data["Èù¢Á©ç"] = m_area.group(1)
    
    # ‰øÆÊ≠£ÔºöÂÖ¨ÂëäÁèæÂÄº
    m_price = re.search(r'ÂÖ¨ÂëäÂúüÂú∞ÁèæÂÄº.*?(\d+)\s*ÂÖÉ', text)
    if m_price: data["ÂÖ¨ÂëäÂúüÂú∞ÁèæÂÄº"] = m_price.group(1)
    
    # ‰øÆÊ≠£ÔºöÊâÄÊúâÊ¨ä‰∫∫
    m_owner = re.search(r'ÊâÄÊúâÊ¨ä‰∫∫\s*[,Ôºå]?\s*([^\s,Ôºå]+)', text)
    if m_owner: data["ÊâÄÊúâÊ¨ä‰∫∫"] = m_owner.group(1).replace('*', 'Ôºä')
    
    # ‰øÆÊ≠£ÔºöÁµ±‰∏ÄÁ∑®Ëôü
    m_id = re.search(r'Áµ±‰∏ÄÁ∑®Ëôü\s*[,Ôºå]?\s*([A-Z\d\*]+)', text)
    if m_id: data["Áµ±‰∏ÄÁ∑®Ëôü"] = m_id.group(1)

    # ‰øÆÊ≠£ÔºöÂú∞ÂùÄ
    m_addr = re.search(r'Âú∞\s*ÂùÄ\s*[,Ôºå]?\s*(.+)', text)
    if m_addr: data["Âú∞ÂùÄ"] = m_addr.group(1).strip()
    
    return data

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 4. UI ‰ªãÈù¢
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.set_page_config(page_title="Âú∞ÊîøËß£Ë≠ØÁ©©ÂÆöÁâà", layout="wide")
ocr_engine = load_ocr()

def main():
    st.title("üè† Âú∞Êîø AI Êô∫ÊÖßËß£Ë≠Ø (Èõ≤Á´ØÂêåÊ≠•Á©©ÂÆöÁâà)")
    
    if 'main_df' not in st.session_state: st.session_state.main_df = None
    if 'raw_txts' not in st.session_state: st.session_state.raw_txts = {}

    files = st.file_uploader("‰∏äÂÇ≥ PDF", type="pdf", accept_multiple_files=True)
    
    if files and st.button("üöÄ ÈñãÂßãÂÖ®Ëá™ÂãïËß£Ë≠Ø"):
        rows = []
        for f in files:
            with st.spinner(f"Ê≠£Âú®ÂàÜÊûê {f.name}..."):
                pdf_bytes = f.read()
                all_imgs = convert_from_bytes(pdf_bytes, dpi=300, poppler_path=POPPLER_PATH)
                with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
                    first_text = pdf.pages[0].extract_text() or ""
                    # ‰æùÊìöÊ®ôÁ±§Âà§ÂÆö‰ΩøÁî®Âì™Á®ÆËß£ÊûêÂô® (ÂÆåÂÖ®‰øùÁïôÂéüÂàÜÈ°ûÈÇèËºØ)
                    if any(k in first_text for k in ["Ë¨ÑÊú¨Á®ÆÈ°ûÁ¢º", "ÂàóÂç∞ÊôÇÈñì"]):
                        txt, _ = process_Ë¨ÑÊú¨(pdf, ocr_engine, all_imgs)
                    elif "‰∏ÄË¶ΩË°®" in first_text:
                        txt, _ = process_Áæ§Áíá(pdf, ocr_engine, all_imgs)
                    else:
                        fmt = "ÂÖâÁâπ" if "Á∏£Â∏Ç" in normalize(first_text) else "ËèØÂÆâ"
                        txt, _ = process_Ë°®Ê†ºÂºè(pdf, ocr_engine, all_imgs, fmt)
                
                st.session_state.raw_txts[f.name] = txt
                rows.append(parse_for_excel(txt))
        st.session_state.main_df = pd.DataFrame(rows)

    if st.session_state.main_df is not None:
        st.subheader("üìù ÊàêÊûú‰øÆÊ≠£ÂçÄ")
        edited_df = st.data_editor(st.session_state.main_df, num_rows="fixed")
        
        if st.button("üß† Á¢∫Ë™ç‰øÆÊ≠£‰∏¶Ë®ìÁ∑¥ AI (Ê∞∏‰πÖÂÑ≤Â≠ò)"):
            for idx in range(len(edited_df)):
                for col in ["Âú∞ÂùÄ", "ÊâÄÊúâÊ¨ä‰∫∫"]:
                    old_v = str(st.session_state.main_df.iloc[idx][col])
                    new_v = str(edited_df.iloc[idx][col])
                    if old_v != new_v and old_v != "":
                        save_to_cloud(old_v, new_v)
            st.session_state.main_df = edited_df
            st.success("üéâ AI Â≠∏ÁøíÊàêÂäüÔºÅ‰∏ãÊ¨°ÈÅáÂà∞Áõ∏ÂêåÂÖßÂÆπÂ∞áËá™ÂãïÊ†°Ê≠£„ÄÇ")

        col1, col2 = st.columns(2)
        with col1:
            xlsx_io = io.BytesIO()
            edited_df.to_excel(xlsx_io, index=False)
            st.download_button("üì• ‰∏ãËºâ Excel Â†±Ë°®", xlsx_io.getvalue(), "Âú∞ÊîøÂΩôÊï¥.xlsx")
        
        with col2:
            z_io = io.BytesIO()
            with zipfile.ZipFile(z_io, "w") as zf:
                for fname, content in st.session_state.raw_txts.items():
                    # ÈáçÈªûÔºöËÆì TXT ‰∏ãËºâÊôÇ‰πüÂêåÊ≠•Èõ≤Á´Ø‰øÆÊ≠£
                    final_txt = ai_smart_fix(content)
                    zf.writestr(f"{fname}.txt", final_txt)
            st.download_button("üì¶ ‰∏ãËºâ‰øÆÊ≠£ÂæåÁöÑ TXT (ZIP)", z_io.getvalue(), "results.zip")

if __name__ == "__main__":
    main()