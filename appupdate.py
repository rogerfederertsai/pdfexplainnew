import streamlit as st
import pdfplumber
import io
import re
import cv2
import numpy as np
from pdf2image import convert_from_bytes
import easyocr
import zipfile
import unicodedata
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. é›²ç«¯è¨˜æ†¶æ¨¡çµ„ (æ–°å¢ï¼šä¸å½±éŸ¿åŸè§£æé‚è¼¯)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_gsheet_client():
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    try:
        creds_info = st.secrets["gcp_service_account"]
        creds = Credentials.from_service_account_info(creds_info, scopes=scopes)
        gc = gspread.authorize(creds)
        return gc.open("åœ°æ”¿AIå­¸ç¿’åº«").sheet1
    except: return None

def load_cloud_memory():
    sheet = get_gsheet_client()
    if sheet:
        try:
            records = sheet.get_all_records()
            return {str(r['wrong']): str(r['right']) for r in records if 'wrong' in r}
        except: return {}
    return {}

def save_to_cloud(wrong, right):
    sheet = get_gsheet_client()
    if sheet:
        try: sheet.append_row([str(wrong), str(right)])
        except: pass

def ai_smart_fix(text):
    """é€™æ˜¯ä¸€å€‹æ¿¾é¡ï¼Œåªåœ¨æœ€å¾Œé¡¯ç¤ºæˆ–åŒ¯å‡ºæ™‚æ‰å°æ–‡å­—é€²è¡Œæ›¿æ›"""
    if not text: return text
    memory = load_cloud_memory()
    for wrong, right in memory.items():
        if str(wrong) in text:
            text = text.replace(str(wrong), str(right))
    return text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. åŸæœ‰æˆåŠŸè¾¨è­˜é‚è¼¯ (å®Œå…¨ä¿ç•™ï¼Œä¸ä½œä»»ä½•æ›´å‹•)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

LOCAL_POPPLER_PATH = r"C:\Users\User\Desktop\pdf_explain new\poppler-25.12.0\Library\bin"
POPPLER_PATH = LOCAL_POPPLER_PATH if os.path.exists(LOCAL_POPPLER_PATH) else None

@st.cache_resource
def load_ocr():
    return easyocr.Reader(['ch_tra', 'en'], gpu=False)

def normalize(text):
    if not text: return ""
    return unicodedata.normalize("NFKC", re.sub(r'\s+', '', text))

# æ‚¨åŸæœ‰çš„ OCR ç­–ç•¥
def fix_addr_post_process(text: str) -> str:
    if not text: return text
    # å°‡ AI ä¿®æ­£æ›åœ¨åŸæ ¡æ­£çš„ç¬¬ä¸€æ­¥
    text = ai_smart_fix(text)
    _ADDR_CHAR_MAP = {'è€‹': 'è‡º', 'è€¸': 'è‡º', 'å­¿': 'å­¸', 'å­½': 'å­¸', 'å£†': 'å­¸', 'è¦ƒ': 'å—'}
    for wrong, right in _ADDR_CHAR_MAP.items():
        text = text.replace(wrong, right)
    text = re.sub(r'(\d)\s+(\d)', r'\1\2', text)
    _ADDR_CJK = r'[é‡Œé„°è·¯æ®µå··å¼„è™Ÿè¡—å€å¸‚ç¸£é„‰é®æ‘]'
    text = re.sub(rf'({_ADDR_CJK})\s+(\d)', r'\1\2', text)
    text = re.sub(rf'(\d)\s+({_ADDR_CJK})', r'\1\2', text)
    return text

def ocr_with_best_result(ocr, img_gray: np.ndarray) -> tuple:
    fx, fy = 4, 4
    b1 = cv2.resize(img_gray, None, fx=fx, fy=fy, interpolation=cv2.INTER_LANCZOS4)
    results = ocr.readtext(b1, detail=0)
    raw = "".join(results).strip()
    processed = fix_addr_post_process(raw)
    return processed, "Standard"

def extract_addr_from_image_stream(page, ocr, debug_log: list):
    words = page.extract_words()
    target = next((w for w in words if w['text'] in ['åœ°å€', 'ä½å€']), None)
    if not target: return ""
    addr_imgs = [img for img in page.images if abs(img['top'] - target['top']) < 5]
    if not addr_imgs: return ""
    try:
        raw = addr_imgs[0]['stream'].get_data()
        buf = np.frombuffer(raw, dtype=np.uint8)
        decoded = cv2.imdecode(buf, cv2.IMREAD_GRAYSCALE)
        val, _ = ocr_with_best_result(ocr, decoded)
        return f"{target['text']} {val}"
    except: return ""

# åŸæœ‰ä¸‰å¤§è§£æå‡½å¼ (å®Œå…¨ä¿ç•™å…§å®¹)
def process_è¡¨æ ¼å¼(pdf, ocr, all_imgs, fmt):
    output, debug = [], []
    for i, page in enumerate(pdf.pages):
        page_text = []
        tables = page.extract_tables()
        for table in tables:
            for row in table:
                cells = [c.strip().replace("\n", "") if c else "" for c in row]
                if not any(cells): continue
                if normalize(cells[0]) in ["åœ°å€", "ä½å€"] and not any(cells[1:]):
                    line = extract_addr_from_image_stream(page, ocr, debug)
                else:
                    line = "  ".join(c for c in cells if c)
                page_text.append(line)
        output.append(f"===== ç¬¬ {i+1} é  =====\n" + "\n".join(page_text))
    return "\n\n".join(output), debug

def process_ç¾¤ç’‡(pdf, ocr, all_imgs):
    output = []
    for i, page in enumerate(pdf.pages):
        lines = [ "  ".join(filter(None, [c.replace("\n","") for c in row])) for table in page.extract_tables() for row in table ]
        output.append(f"===== ç¬¬ {i+1} é  =====\n" + "\n".join(lines))
    return "\n\n".join(output), []

def process_è¬„æœ¬(pdf, ocr, all_imgs):
    output = []
    for i, page in enumerate(pdf.pages):
        txt = page.extract_text() or ""
        output.append(f"===== ç¬¬ {i+1} é  =====\n" + txt)
    return "\n\n".join(output), []

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Excel çµæ§‹åŒ–è§£æ (ä¾ç…§ sample.xlsx èª¿æ•´æ¬„ä½)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_for_excel(text):
    # å…ˆå¥—ç”¨ AI ä¿®æ­£ï¼Œç¢ºä¿æ¬„ä½æ“·å–æ™‚å°±æ˜¯å°çš„
    text = ai_smart_fix(text)
    
    # å°é½Š sample.xlsx çš„æ¬„ä½æ ¼å¼
    data = {
        "åœ°è™Ÿå…¨å": "", "åœ°è™Ÿ": "", "é¢ç©": "", 
        "å…¬å‘ŠåœŸåœ°ç¾å€¼": "", "æ‰€æœ‰æ¬Šäºº": "", "çµ±ä¸€ç·¨è™Ÿ": "", "åœ°å€": ""
    }
    
    # è¡Œæ”¿å€èˆ‡æ®µ
    m_loc = re.search(r'([^\s]+(?:ç¸£|å¸‚)[^\s]+(?:å€|é„‰|é®|å¸‚)[^\s]+æ®µ)', text)
    if m_loc: data["åœ°è™Ÿå…¨å"] = m_loc.group(1)
    
    # åœ°è™Ÿ (1437-0000)
    m_no = re.search(r'(\d{4}-\d{4})', text)
    if m_no: data["åœ°è™Ÿ"] = m_no.group(1)
    
    # é¢ç© (æŠ“å–æ•¸å­—)
    m_area = re.search(r'é¢ç©\s*[,ï¼Œ]?\s*([\d.]+)', text)
    if m_area: data["é¢ç©"] = m_area.group(1)
    
    # å…¬å‘Šç¾å€¼
    m_price = re.search(r'å…¬å‘ŠåœŸåœ°ç¾å€¼.*?(\d+)\s*å…ƒ', text)
    if m_price: data["å…¬å‘ŠåœŸåœ°ç¾å€¼"] = m_price.group(1)
    
    # æ‰€æœ‰æ¬Šäºº (è”¡**)
    m_owner = re.search(r'æ‰€æœ‰æ¬Šäºº\s*[,ï¼Œ]?\s*([^\s,ï¼Œ]+)', text)
    if m_owner: data["æ‰€æœ‰æ¬Šäºº"] = m_owner.group(1).replace('*', 'ï¼Š')
    
    # çµ±ä¸€ç·¨è™Ÿ
    m_id = re.search(r'çµ±ä¸€ç·¨è™Ÿ\s*[,ï¼Œ]?\s*([A-Z\d\*]+)', text)
    if m_id: data["çµ±ä¸€ç·¨è™Ÿ"] = m_id.group(1)

    # åœ°å€
    m_addr = re.search(r'åœ°\s*å€\s*[,ï¼Œ]?\s*(.+)', text)
    if m_addr: data["åœ°å€"] = m_addr.group(1).strip()
    
    return data

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. Streamlit ä»‹é¢é‚è¼¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="åœ°æ”¿æ™ºæ…§è§£è­¯ç©©å®šç‰ˆ", layout="wide")
ocr_engine = load_ocr()

def main():
    st.title("ğŸ  åœ°æ”¿ AI æ™ºæ…§è§£è­¯ (é›²ç«¯åŒæ­¥ç©©å®šç‰ˆ)")
    
    if 'main_df' not in st.session_state: st.session_state.main_df = None
    if 'raw_txts' not in st.session_state: st.session_state.raw_txts = {}

    files = st.file_uploader("ä¸Šå‚³ PDF", type="pdf", accept_multiple_files=True)
    
    if files and st.button("ğŸš€ é–‹å§‹æ·±åº¦è¾¨è­˜"):
        rows = []
        for f in files:
            with st.spinner(f"è™•ç†ä¸­: {f.name}"):
                pdf_bytes = f.read()
                all_imgs = convert_from_bytes(pdf_bytes, dpi=300, poppler_path=POPPLER_PATH)
                with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
                    first_text = pdf.pages[0].extract_text() or ""
                    if any(k in first_text for k in ["è¬„æœ¬ç¨®é¡ç¢¼", "åˆ—å°æ™‚é–“"]):
                        txt, _ = process_è¬„æœ¬(pdf, ocr_engine, all_imgs)
                    elif "ä¸€è¦½è¡¨" in first_text:
                        txt, _ = process_ç¾¤ç’‡(pdf, ocr_engine, all_imgs)
                    else:
                        fmt = "å…‰ç‰¹" if "ç¸£å¸‚" in normalize(first_text) else "è¯å®‰"
                        txt, _ = process_è¡¨æ ¼å¼(pdf, ocr_engine, all_imgs, fmt)
                
                st.session_state.raw_txts[f.name] = txt
                rows.append(parse_for_excel(txt))
        st.session_state.main_df = pd.DataFrame(rows)

    if st.session_state.main_df is not None:
        st.subheader("ğŸ“ ä¿®æ­£èˆ‡ AI è¨“ç·´")
        # é¡¯ç¤ºç·¨è¼¯å™¨
        edited_df = st.data_editor(st.session_state.main_df, num_rows="fixed")
        
        if st.button("ğŸ§  ç¢ºèªä¿®æ­£ä¸¦è¨“ç·´ AI"):
            for idx in range(len(edited_df)):
                for col in ["åœ°å€", "æ‰€æœ‰æ¬Šäºº"]:
                    old_v = str(st.session_state.main_df.iloc[idx][col])
                    new_v = str(edited_df.iloc[idx][col])
                    if old_v != new_v and old_v != "":
                        save_to_cloud(old_v, new_v)
            st.session_state.main_df = edited_df
            st.success("AI å·²ç´€éŒ„ä¿®æ­£ï¼Œä¸‹è¼‰æª”å°‡å¥—ç”¨æ–°è¦å‰‡ã€‚")

        # â”€â”€â”€â”€â”€â”€ ä¸‹è¼‰å€ (é‡é»ï¼šè§£æ±ºå•é¡Œ 1 èˆ‡ 2) â”€â”€â”€â”€â”€â”€
        col1, col2 = st.columns(2)
        with col1:
            # ç”¢å‡º Excel
            xlsx_io = io.BytesIO()
            edited_df.to_excel(xlsx_io, index=False)
            st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel å ±è¡¨", xlsx_io.getvalue(), "åœ°æ”¿å½™æ•´.xlsx")

        with col2:
            # ä¸‹è¼‰ TXT (é‡é»ï¼šåœ¨æ­¤è™•é‡æ–°ä¿®æ­£ TXT)
            z_io = io.BytesIO()
            with zipfile.ZipFile(z_io, "w") as zf:
                for fname, content in st.session_state.raw_txts.items():
                    # åœ¨å¯«å…¥ ZIP å‰ï¼Œå°‡åŸå§‹æ–‡å­—å†è·‘ä¸€æ¬¡ AI ä¿®æ­£æ¿¾é¡
                    final_txt = ai_smart_fix(content)
                    zf.writestr(f"{fname}.txt", final_txt)
            st.download_button("ğŸ“¦ ä¸‹è¼‰ä¿®æ­£å¾Œçš„ TXT (ZIP)", z_io.getvalue(), "results.zip")

if __name__ == "__main__":
    main()